{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:03.262034Z",
     "start_time": "2022-05-18T20:49:03.021790Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load downloaded model for face detection\n",
    "https://gist.github.com/Learko/8f51e58ac0813cb695f3733926c77f52#file-haarcascade_frontalface_default-xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:03.979278Z",
     "start_time": "2022-05-18T20:49:03.925279Z"
    }
   },
   "outputs": [],
   "source": [
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to extract faces from the image or frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:04.904750Z",
     "start_time": "2022-05-18T20:49:04.884668Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "        rect = [(x, y), (x + w, y + h)]\n",
    "        \n",
    "    return cropped_face, rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo visualisation of extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:07.796103Z",
     "start_time": "2022-05-18T20:49:07.749110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing sample image\n",
    "image = cv2.imread(\"../DATA/two_people.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:08.467366Z",
     "start_time": "2022-05-18T20:49:08.222772Z"
    }
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "faces = face_classifier.detectMultiScale(gray, 1.3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:08.765534Z",
     "start_time": "2022-05-18T20:49:08.756534Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definition to display images\n",
    "def disp_op(label, image):\n",
    "    cv2.imshow(label, image)\n",
    "\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:09.279271Z",
     "start_time": "2022-05-18T20:49:09.261269Z"
    }
   },
   "outputs": [],
   "source": [
    "cropped_face = []\n",
    "for (x,y,w,h) in faces:\n",
    "     cropped_face.append(image[y:y+h, x:x+w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:09.994874Z",
     "start_time": "2022-05-18T20:49:09.972861Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[235,  30, 172, 172],\n",
       "       [786,  64, 172, 172]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:49:21.526007Z",
     "start_time": "2022-05-18T20:49:10.509285Z"
    }
   },
   "outputs": [],
   "source": [
    "disp_op(\"face\", cropped_face[1]) # you can change index according to number of faces in image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting face images of the user for training data for image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:51:56.066767Z",
     "start_time": "2022-05-18T20:51:56.045767Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_user():\n",
    "    T = int(input())\n",
    "    users=[]\n",
    "    for t in range(T):\n",
    "        name = input(\"Enter username : \")\n",
    "        name = str(name)\n",
    "        users.append(name)\n",
    "    \n",
    "#         newpath = 'faces/' + name\n",
    "#         if not os.path.exists(newpath):\n",
    "#             os.makedirs(newpath)\n",
    "\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        count = 0\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if face_extractor(frame) is not None:\n",
    "                count +=1\n",
    "                face = cv2.resize(face_extractor(frame)[0], (200, 200))\n",
    "                rect = face_extractor(frame)[1]\n",
    "                face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                file_name_path = 'faces/' + name + str(count) + '.jpg'\n",
    "\n",
    "                cv2.imwrite(file_name_path, face)\n",
    "                cv2.putText(frame, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.rectangle(frame, rect[0], rect[1], (0, 255, 255), 2)\n",
    "                cv2.imshow('FACE CROPPER', frame)\n",
    "                \n",
    "            else:\n",
    "                print('face not found')\n",
    "\n",
    "            if cv2.waitKey(1) == 13 or count == 200:\n",
    "                break\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"Collecting {} Data Complete !!!\".format(name))\n",
    "    \n",
    "    print(\" All {} users data collected\".format(T))\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:01.874187Z",
     "start_time": "2022-05-18T20:52:05.061549Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Enter username : Nim\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "Collecting Nim Data Complete !!!\n",
      "Enter username : Sau\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "face not found\n",
      "Collecting Sau Data Complete !!!\n",
      " All 2 users data collected\n"
     ]
    }
   ],
   "source": [
    "users = add_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have collected face images data of user to be used for training. We can collect more images with different head poses for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:17.200923Z",
     "start_time": "2022-05-18T20:54:17.180953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nim', 'Sau']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:28.832938Z",
     "start_time": "2022-05-18T20:54:28.828939Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:29.394913Z",
     "start_time": "2022-05-18T20:54:29.356632Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = 'faces/'\n",
    "onlyfiles= [f for f in listdir(data_path) if isfile(join(data_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:39.423328Z",
     "start_time": "2022-05-18T20:54:39.413329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nim1.jpg'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onlyfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:54:40.699823Z",
     "start_time": "2022-05-18T20:54:40.685777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onlyfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:58:33.005426Z",
     "start_time": "2022-05-18T20:58:32.813196Z"
    }
   },
   "outputs": [],
   "source": [
    "Train_Data, Labels = [], []\n",
    "\n",
    "for file in onlyfiles:\n",
    "    image_path = data_path + file\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    Train_Data.append(np.asarray(image, dtype=np.uint8))\n",
    "    Label = ''.join(filter(str.isalpha,file.split('.')[-2]))\n",
    "    index = users.index(Label)\n",
    "    \n",
    "    Labels.append(index)\n",
    "    \n",
    "Labels = np.asarray(Labels, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:58:33.538507Z",
     "start_time": "2022-05-18T20:58:33.517460Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:58:36.175649Z",
     "start_time": "2022-05-18T20:58:34.581480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trainig Complete !!!\n"
     ]
    }
   ],
   "source": [
    "# Linear Binary Phase Histogram Classifier\n",
    "\n",
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(np.asarray(Train_Data), np.asarray(Labels))\n",
    "print('Model Trainig Complete !!!')\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "if above line throws error, then run following command \n",
    "\n",
    "> python -m pip install --user opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:09:40.329926Z",
     "start_time": "2022-05-18T21:09:40.308933Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_detector(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, )\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "        \n",
    "    return img, roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:15:43.686408Z",
     "start_time": "2022-05-18T21:14:45.006710Z"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    image, face = face_detector(frame)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        result = model.predict(face)\n",
    "        \n",
    "        if result[1] < 500:\n",
    "            confidence = int(100*(1-(result[1]) / 300))\n",
    "            display_string = str(confidence) + '% Confidence it is USER - ' + users[result[0]]\n",
    "            \n",
    "        cv2.putText(image, display_string, (100, 100), cv2.FONT_HERSHEY_COMPLEX_SMALL, 1, (255, 120, 255), 2)\n",
    "        \n",
    "        if confidence > 75:\n",
    "            cv2.putText(image, \"Unlocked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 55, 255), 2)\n",
    "            cv2.imshow(\"Face Cropper\", image)\n",
    "            \n",
    "        else:\n",
    "            cv2.putText( image, \"Locked\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 55, 0), 2)\n",
    "            cv2.imshow(\"Face Cropper\", image)\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, \"Face Not Found\", (250, 450), cv2.FONT_HERSHEY_COMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        cv2.imshow(\"Face Cropper\", image)\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:12:04.729987Z",
     "start_time": "2022-05-18T21:12:04.657990Z"
    }
   },
   "outputs": [],
   "source": [
    "face = cv2.imread(\"faces/Sau1.jpg\")\n",
    "face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "result = model.predict(face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:12:08.503805Z",
     "start_time": "2022-05-18T21:12:08.495813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
